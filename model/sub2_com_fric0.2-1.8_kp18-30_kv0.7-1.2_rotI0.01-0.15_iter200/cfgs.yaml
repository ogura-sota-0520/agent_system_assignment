env_cfg:
  num_actions: 12
  default_joint_angles:
    FL_hip_joint: 0.0
    FR_hip_joint: 0.0
    RL_hip_joint: 0.0
    RR_hip_joint: 0.0
    FL_thigh_joint: 0.8
    FR_thigh_joint: 0.8
    RL_thigh_joint: 1.0
    RR_thigh_joint: 1.0
    FL_calf_joint: -1.5
    FR_calf_joint: -1.5
    RL_calf_joint: -1.5
    RR_calf_joint: -1.5
  dof_names:
  - FR_hip_joint
  - FR_thigh_joint
  - FR_calf_joint
  - FL_hip_joint
  - FL_thigh_joint
  - FL_calf_joint
  - RR_hip_joint
  - RR_thigh_joint
  - RR_calf_joint
  - RL_hip_joint
  - RL_thigh_joint
  - RL_calf_joint
  kp: 20.0
  kd: 0.5
  termination_if_roll_greater_than: 10
  termination_if_pitch_greater_than: 10
  base_init_pos:
  - 0.0
  - 0.0
  - 0.42
  base_init_quat:
  - 1.0
  - 0.0
  - 0.0
  - 0.0
  episode_length_s: 20.0
  resampling_time_s: 4.0
  action_scale: 0.25
  simulate_action_latency: true
  clip_actions: 100.0
  substeps: 2
obs_cfg:
  num_obs: 45
  obs_scales:
    lin_vel: 2.0
    ang_vel: 0.25
    dof_pos: 1.0
    dof_vel: 0.05
reward_cfg:
  tracking_sigma: 0.25
  base_height_target: 0.3
  feet_height_target: 0.075
  reward_scales:
    tracking_lin_vel: 0.02
    tracking_ang_vel: 0.004
    lin_vel_z: -0.02
    base_height: -1.0
    action_rate: -0.0001
    similar_to_default: -0.002
command_cfg:
  num_commands: 3
  lin_vel_x_range:
  - 0
  - 0.5
  lin_vel_y_range:
  - -0.05
  - 0.05
  ang_vel_range:
  - -0.3
  - 0.3
train_cfg:
  algorithm:
    clip_param: 0.2
    desired_kl: 0.01
    entropy_coef: 0.01
    gamma: 0.99
    lam: 0.95
    learning_rate: 0.001
    max_grad_norm: 1.0
    num_learning_epochs: 5
    num_mini_batches: 4
    schedule: adaptive
    use_clipped_value_loss: true
    value_loss_coef: 1.0
  init_member_classes: {}
  policy:
    activation: elu
    actor_hidden_dims:
    - 512
    - 256
    - 128
    critic_hidden_dims:
    - 512
    - 256
    - 128
    init_noise_std: 1.0
  runner:
    algorithm_class_name: PPO
    checkpoint: -1
    experiment_name: go2-walking
    load_run: -1
    log_interval: 1
    max_iterations: 200
    num_steps_per_env: 24
    policy_class_name: ActorCritic
    record_interval: -1
    resume: false
    resume_path: null
    run_name: ''
    runner_class_name: runner_class_name
    save_interval: 100
  runner_class_name: OnPolicyRunner
  seed: 1
